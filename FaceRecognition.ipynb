{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMwUDiWcqrafnbMAvsGlnya",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giova0/proyectoAsistencIA/blob/main/FaceRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6hw0n34Z_0j",
        "outputId": "c8bef4b3-84bb-4d22-fbb4-aeea6aff8ae9"
      },
      "source": [
        "## Instalación para lectura de hojas spreadsheet\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "##cargar hojas Base y NuevasFotos\n",
        "worksheet1 = gc.open('ListadoFotos').sheet1  # LLamar hoja base \n",
        "#DataFrames\n",
        "rows1 = worksheet1.get_all_values()   ## row1 en hoja 1\n",
        "df1=pd.DataFrame(rows1)               ## Dataframe hoja 1\n",
        "print(df1[5][2])  ## foto base todo el [5][2-28]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://nodo1.vpsnotas.com/evalweb/api/Exportacion/10957/FotoAgenda/Codigo=1710003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N7MNCYdVF2Z",
        "outputId": "d380f2bf-c163-48bf-a4ed-e5f463814d66"
      },
      "source": [
        "pip install --upgrade azure-cognitiveservices-vision-face  ## Instalar la biblioteca de cliente"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting azure-cognitiveservices-vision-face\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/94/1916bebc3e70d4ad3108c43ee366d61e0ba8784c33853eb8cfa19a6ef775/azure_cognitiveservices_vision_face-0.5.0-py2.py3-none-any.whl (66kB)\n",
            "\r\u001b[K     |█████                           | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 20kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 30kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 61kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.2MB/s \n",
            "\u001b[?25hCollecting azure-common~=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/1e/cfe7987493242e8b9ead309cfd76fc500c38bbefe192192b813325d289f3/azure_common-1.1.27-py2.py3-none-any.whl\n",
            "Collecting msrest>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/cc/6c96bfb3d3cf4c3bdedfa6b46503223f4c2a4fa388377697e0f8082a4fed/msrest-0.6.21-py2.py3-none-any.whl (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (2020.12.5)\n",
            "Collecting isodate>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests~=2.16 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-face) (3.1.0)\n",
            "Installing collected packages: azure-common, isodate, msrest, azure-cognitiveservices-vision-face\n",
            "Successfully installed azure-cognitiveservices-vision-face-0.5.0 azure-common-1.1.27 isodate-0.6.0 msrest-0.6.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USwaaz_HVFop"
      },
      "source": [
        "##Arroja la identificacion de una imagen en la web\n",
        "\n",
        "import asyncio\n",
        "import io\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import uuid\n",
        "import requests\n",
        "import urllib\n",
        "from urllib.parse import urlparse\n",
        "from io import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from azure.cognitiveservices.vision.face import FaceClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ5OBVV-aN4R"
      },
      "source": [
        "# Create an authenticated FaceClient.\n",
        "KEY = '326d364a0fbe4a39998455172d1a3b46'\n",
        "ENDPOINT = 'https://servicioface.cognitiveservices.azure.com/'\n",
        "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXAyyaZwVFyb",
        "outputId": "02fd88ef-2a94-4a46-d12c-8284c77f5879"
      },
      "source": [
        "# Códigos de fotos para una cadena de textos\n",
        "\n",
        "L1=[]\n",
        "L2=[]\n",
        "def f(a1, L_tarea_columna53=[]):\n",
        "  L1.append(a1)\n",
        "def f(a2, L_tarea_columna53=[]):\n",
        "  L1.append(a2)\n",
        "\n",
        "for i in range(2, 8):\n",
        "  single_image_name = os.path.basename(df1[5][i])\n",
        "  detected_faces = face_client.face.detect_with_url(url=df1[5][i], detection_model='detection_03')\n",
        "  if not detected_faces:\n",
        "    raise Exception('No face detected from image {}'.format(single_image_name))\n",
        "\n",
        "  for face in detected_faces: \n",
        "    print(df1[2][i],\": \",face.face_id)\n",
        "    L1.append(face.face_id)\n",
        "    L2.append(df1[2][i])\n",
        "    first_image_face_ID = detected_faces[0].face_id\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACERO VILLA JUANA VALENTINA :  52728d53-7e02-4d3a-ac60-00c5ed785368\n",
            "AREVALO CIFUENTES YURIS VANESSA :  0bb6cf81-f32a-4719-a657-11c0fe632bc6\n",
            "ARREDONDO GIRALDO YESSICA PAOLA :  29aa5d0b-6556-430b-b5d8-0fd625c9ab9e\n",
            "CABEZAS CONDE KAROL DAYANA :  dc71412c-5fa2-4432-b2c8-fc3d025b7997\n",
            "CARDENAS MUÑOZ LAURA GINED :  dfb49e51-c06c-4b0e-8827-52bf7c3e3532\n",
            "CASTAÑEDA RAMIREZ KAROL ESTEFANIA :  db3a5e90-7b8d-452d-b3e2-6366787468ca\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnsvEJ8Kovg0"
      },
      "source": [
        "## Imagen a analizar\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8BKJvLZawqP"
      },
      "source": [
        "from google.colab import files     ##Información entrada de archivos\n",
        "from IPython.display import Image  ##Permitir imagenes\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHNN1beOb6PH"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "##uploaded = files.upload()     ##Subir Imagenes\n",
        "#Image('juana.png', width = 100)  ## https://nodo1.vpsnotas.com/evalweb/api/Exportacion/10957/FotoAgenda/Codigo=1710206\n",
        "#Image('karol.png', width = 100)  ## https://nodo1.vpsnotas.com/evalweb/api/Exportacion/10957/FotoAgenda/Codigo=1710206"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhM6Z_WqeR-P"
      },
      "source": [
        "fotoProfe: https://raw.githubusercontent.com/giova0/photosIA/main/p3.jpg\n",
        "\n",
        "<img src=https://raw.githubusercontent.com/giova0/photosIA/main/p3.jpg width=\"100\" height=\"100\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_N5lPsnV71R"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RKjQNlPujWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e475096-25e9-461b-805b-d242402a2117"
      },
      "source": [
        "# Genera un código si la foto detecta un rostro\n",
        "L3=[]\n",
        "def f(a1, L3=[]):\n",
        "  L3.append(a1)\n",
        "\n",
        "foto1 = 'https://nodo1.vpsnotas.com/evalweb/api/Exportacion/10957/FotoAgenda/Codigo=1710206' ## Juana\n",
        "foto2 = 'https://nodo1.vpsnotas.com/evalweb/api/Exportacion/10957/FotoAgenda/Codigo=1710206' ## karol\n",
        "foto3 = 'https://raw.githubusercontent.com/giova0/fotosIA/main/p3.jpg'  ## FotoProfe\n",
        "fotoP = foto2\n",
        "\n",
        "single_image_name = os.path.basename(fotoP)\n",
        "detected_faces = face_client.face.detect_with_url(url=fotoP, detection_model='detection_03')\n",
        "if not detected_faces:\n",
        "    raise Exception('No face detected from image {}'.format(single_image_name))\n",
        "\n",
        "for face in detected_faces: \n",
        "    print(face.face_id)\n",
        "    L3.append(face.face_id)\n",
        "    first_image_face_ID = detected_faces[0].face_id"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4df93146-3083-4909-88b2-af35d708d503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70MBdXytJN4k"
      },
      "source": [
        "t1 = df1[5][2]  # fotos de la misma persona\n",
        "s1 =  fotoP     # Foto nueva "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyIFKi4XKDM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3559351-d9c9-4c7a-bde8-c0fc52b0a44b"
      },
      "source": [
        "d1 = face_client.face.detect_with_url(s1, detection_model='detection_03')\n",
        "s_id = d1[0].face_id\n",
        "print('Hay','{} rostro(s) detectado en la nueva foto: {}.'.format(len(d1), s1))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hay 1 rostro(s) detectado en la nueva foto: https://nodo1.vpsnotas.com/evalweb/api/Exportacion/10957/FotoAgenda/Codigo=1710206.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj5K0MKR73-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e480bece-e7f2-4dd1-876d-1ef5d54e3429"
      },
      "source": [
        "#Nivel de similaridad\n",
        "L4=[]\n",
        "L5=[]\n",
        "def f(a1, L4=[]):\n",
        "  L4.append(a1)\n",
        "for ii in range(0,6): \n",
        "  vrs = face_client.face.verify_face_to_face(d1[0].face_id, L1[ii])\n",
        "  print('{} es similar, con: {}'.format(L2[ii], vrs.confidence)\n",
        "  if vrs.is_identical\n",
        "  else '{} es poco similar, con: {}'.format(L2[ii], vrs.confidence))\n",
        "  L4.append(vrs.confidence)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACERO VILLA JUANA VALENTINA es poco similar, con: 0.11014\n",
            "AREVALO CIFUENTES YURIS VANESSA es poco similar, con: 0.24235\n",
            "ARREDONDO GIRALDO YESSICA PAOLA es poco similar, con: 0.261\n",
            "CABEZAS CONDE KAROL DAYANA es poco similar, con: 0.30342\n",
            "CARDENAS MUÑOZ LAURA GINED es poco similar, con: 0.28223\n",
            "CASTAÑEDA RAMIREZ KAROL ESTEFANIA es similar, con: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r__BDBUvkeDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06744a22-075c-48e7-a5fb-3e46f0c359c7"
      },
      "source": [
        "L5=[]\n",
        "def f(a1, L5=[]):\n",
        "  L5.append(a1)\n",
        "for iii in range(0,6): \n",
        "  if L4[iii] >= 0.8:\n",
        "    print(\"La foto es similar a: \", L2[iii])\n",
        "    L5.append(L2[iii])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La foto es similar a:  CASTAÑEDA RAMIREZ KAROL ESTEFANIA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1VFfZD_qQJ5"
      },
      "source": [
        "# Envío informacion a la hoja de asistencia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxttrvhEqOHj"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYBDgmIBqOLq"
      },
      "source": [
        "worksheet1 = gc.open('HojaAsistencIA').sheet1  # LLamar hoja de drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rECA7WFGqOSd"
      },
      "source": [
        "#DataFrames\n",
        "rows1 = worksheet1.get_all_values()   ## row1 en hoja 1\n",
        "dff1=pd.DataFrame(rows1)               ## Dataframe hoja 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeQHOeu_ucf7"
      },
      "source": [
        "## Modificación Hoja\n",
        "worksheet1.update_cell(2, 2, L5[0])   ## se puede variar la vila en el primer 2 "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}